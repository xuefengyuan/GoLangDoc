[TOC]

# 二、进阶篇

### 1、slice扩容后，容量及内存如何计算？

#### 1.1、扩容后预估容量

假设现在有一个长度为2的切片，对其进行扩容，增加三个元素

```go
sli := []int{1,2}
sli = append(sli,3,4,5)
```

 对于扩容后的切片，长度为5，这一点没有争议。

但容量呢？也是5吗？

经过运行验证，实际的容量为6。容量为6是如何计算出来的呢？

在Go的源码中`runtime/slice.go`关于slice扩容增长的代码如下：

```go
newcap := old.cap

if newcap + newcap < cap {
    newcap = cap
} else {
    for {
        if old.len < 1024 {
            newcap += newcap
        } else {
            newcap += newcap / 4
        }
        if newcap > cap{
            break
        }
    }
}
```

上面代码，只理解前两行

- 第一行的 old.cap：扩容前的容量，对于示例，就是2
- 第二行的cap：扩容前容量加上扩容的元素数量，对于示例，就是2+3

整段代码的核心就是要计算出扩容后的预估容量，也就是newcap，计算逻辑是：

1. 若old.cap *2 小于 cap，那么newcap就取大的cap
2. 若old.cap*2 大于 cap，并且old.cap小于1024，那么newcap还是取大，即newcap = old.cap * 2
3. 若old.cap*2 大于 cap， 但old.cap大于1024，那两倍冗余可能就有点大了，系数换成1.25，即newcap = old.cap * 1.25

但newcap只是预估容量，并不是最终容量，要计算最终的容量，还要参考另一个维度，也就是内存分配。

#### 1.2、内存分配规律

举个例子：

家里有五个人，每个人都想吃绿豆糕，因此你的需求就是5，对应上例中的cap，于是你就到超市里去买。

但超市并不是你家开的，绿豆糕都是整盒整盒卖的，没有散装的，每盒的数量是6个，因止你最少买6个。

每次购买最少数量，就可以类比做Go的内存分配规律。

只有在了解了Go的内存分配规律，我们才能准确的计算出我们最少得买多少绿豆糕（得申请多少的内存，分配多少的容量）

内存管理模块的代码位置在`runtime/sizeclassesgo`

```go
// class  bytes/obj  bytes/span  objects  tail waste  max waste  min align
//     1          8        8192     1024           0     87.50%          8
//     2         16        8192      512           0     43.75%         16
//     3         24        8192      341           8     29.24%          8
//     4         32        8192      256           0     21.88%         32
//     5         48        8192      170          32     31.52%         16
//     6         64        8192      128           0     23.44%         64
//     7         80        8192      102          32     19.07%         16
//     8         96        8192       85          32     15.95%         32
//     9        112        8192       73          16     13.56%         16
//    10        128        8192       64           0     11.72%        128
//    11        144        8192       56         128     11.82%         16
//    12        160        8192       51          32      9.73%         32
//    13        176        8192       46          96      9.59%         16
//    14        192        8192       42         128      9.25%         64
//    15        208        8192       39          80      8.12%         16
//    16        224        8192       36         128      8.15%         32
//    17        240        8192       34          32      6.62%         16
//    18        256        8192       32           0      5.86%        256
//    19        288        8192       28         128     12.16%         32
//    20        320        8192       25         192     11.80%         64
//    21        352        8192       23          96      9.88%         32
//    22        384        8192       21         128      9.51%        128
//    23        416        8192       19         288     10.71%         32
//    24        448        8192       18         128      8.37%         64
//    25        480        8192       17          32      6.82%         32
//    26        512        8192       16           0      6.05%        512
//    27        576        8192       14         128     12.33%         64
//    28        640        8192       12         512     15.48%        128
//    29        704        8192       11         448     13.93%         64
//    30        768        8192       10         512     13.94%        256
//    31        896        8192        9         128     15.52%        128
//    32       1024        8192        8           0     12.40%       1024
//    33       1152        8192        7         128     12.41%        128
//    34       1280        8192        6         512     15.55%        256
//    35       1408       16384       11         896     14.00%        128
//    36       1536        8192        5         512     14.00%        512
//    37       1792       16384        9         256     15.57%        256
//    38       2048        8192        4           0     12.45%       2048
//    39       2304       16384        7         256     12.46%        256
//    40       2688        8192        3         128     15.59%        128
//    41       3072       24576        8           0     12.47%       1024
//    42       3200       16384        5         384      6.22%        128
//    43       3456       24576        7         384      8.83%        128
//    44       4096        8192        2           0     15.60%       4096
//    45       4864       24576        5         256     16.65%        256
//    46       5376       16384        3         256     10.92%        256
//    47       6144       24576        4           0     12.48%       2048
//    48       6528       32768        5         128      6.23%        128
//    49       6784       40960        6         256      4.36%        128
//    50       6912       49152        7         768      3.37%        256
//    51       8192        8192        1           0     15.61%       8192
//    52       9472       57344        6         512     14.28%        256
//    53       9728       49152        5         512      3.64%        512
//    54      10240       40960        4           0      4.99%       2048
//    55      10880       32768        3         128      6.24%        128
//    56      12288       24576        2           0     11.45%       4096
//    57      13568       40960        3         256      9.99%        256
//    58      14336       57344        4           0      5.35%       2048
//    59      16384       16384        1           0     12.49%       8192
//    60      18432       73728        4           0     11.11%       2048
//    61      19072       57344        3         128      3.57%        128
//    62      20480       40960        2           0      6.87%       4096
//    63      21760       65536        3         256      6.25%        256
//    64      24576       24576        1           0     11.45%       8192
//    65      27264       81920        3         128     10.00%        128
//    66      28672       57344        2           0      4.91%       4096
//    67      32768       32768        1           0     12.50%       8192
```

上面这个表格中，可以总结出一些规律。

- 在小于16字节时，每次以8个字节增加
- 当大于16小于2^8时，每次以16字节增加
- 当大于2^8小于2^9时，每次以32字节增加
- 依此规律...

#### 1.3、匹配到合适的内存

第一节中，一个元素类型为int的切片，每个int占用为8个字节，由于我们计算出newcap为5，因此新的切片，最少要占用5*8=40个字节。

第二节中，发现离40 byte最接受的是32和48两个档位。

如果是32 byte，就不够用了，因此只能选择48这个档位去分配内存。

有了实际分配的内存，再回去计算容量，就是扩容后真实的切片容量，也就是`48/8=6`

### 2、goroutine存在的意义是什么？

线程分两种

- 一种是传统意义的操作系统线程。
- 一种是编程语言实现的用户太线程，也就是协和，在GO中就是goroutine

goroutine的存在是为了换个方式解决操作系统线程的一些弊端 - **太重**

太重的表现在如下几个方面

**第一：创建和切换太重**

操作系统线程的创建和切换都需要进入内核，而进入内核消耗的性能代价比较高，开销比较大。

**第二：内存使用太重**

一方面，为了尽量避免极端情况下操作系统线程栈的溢出，内核在创建操作系统线程时默认会为其分配一个较大的栈内存(虚拟地址空间，内核并不会一开始就分配这么多物理内存)，然而在绝大多数情况下，系统线程远远用不了这么多内存，导致浪费。

另一方面，sgt内存空间一旦创建和初始化完成后，其大小就不能再有变化，这决定了在某些特殊场景下系统线程栈还是有溢出的风险。

相对的，用户态的goroutine就轻量得多：

- gorutine是用户态线程，其创建和切换都在用户代码中完成。无需进入操作系统内核，所以开销也要远远小于系统线程的创建和切换。
- goroutine启动时默认栈大小只有2k，在多数情况下已经够用了，即使不够用，goroutine的栈也会自动扩大。同时，如果栈太大了过于浪费它还能自动收缩，这样即没有栈溢出的风险，也不会造成栈内存空间的大量浪费。

### 3、说说Go中的闭包的底层原理？

#### 3.1、什么是闭包？

一个函数内引用了外部的局部变量，这种现象，就称之为闭包。

如下代码，adder的函数返回了一个匿名函数，而该匿名函数中引用了adder函数中的局部变量`sum`，那这个函数就是一个闭包。

```go
func adder() func(int) int {
    sum := 0
    return func(x int) int {
        sum += x
        return sum 
    }
}
```

而这个闭包中引用的外部局部变量并不会随着adder函数的返回而从栈上销毁。

尝试调用这个函数，发现每一次调用，sum的值都会保留在闭包函数中以待使用。

```go
func main() {
    valueFunc := adder() {
        fmt.Println(valueFunc(2))
        fmt.Println(valueFunc(2))
    }
}
```

#### 3.2、复杂的闭包场景

写一个闭包是比较容易的事，会写简单的闭包函数，还远远不够，如果不搞清楚闭包的真正原理，在一些复杂的闭包场景中对函数的执行逻辑就会误判。

下面示例，你觉得会打印是什么，6还是11？

```go
func func1() (i int) {
    i = 10
    defer func() {
        i += 1
    }
    return 5
}

func main() {
    closure := func1()
    fmt.Println(closure)
}
```

#### 3.3、闭包的底层原理

分析示例：

```go
func adder() func(int) int {
    sum := 0
    return func(x int) int {
        sum += x
        return sum 
    }
}

func main() {
    valueFunc := adder() {
        fmt.Println(valueFunc(2))
        fmt.Println(valueFunc(2))
    }
}
```

先对它进行逃逸分析，很容易发现sum作为adder的函数局部变量，并不是分配在栈上，而是分配在堆上的。

那就解决第一个疑惑，**为什么adder函数返回后，sum不会随这销毁**

另外一个一问题又来了，就算它不销毁，那闭包函数若是存储的是sum拷贝后的值，那每次调用闭包函数，里面的sum应该都是一样的，调用两次应该返回2，而不是可以累加记录。

因此，可以大胆猜测，闭包函数的结构体里存储的是sum的指针。

通过下面命令，可以输出对应的汇编代码。

```shell
go build -bcflage="-S" xxx.go
```

输出的内容很多，可以根据自己想要的提取关键代码，它定义了闭包函数的结构体。

其中F是函数指针，sum存储的确实是指针。

```go
type.noalg.struct { F uintptr; "".sum *int }(SB), CX
```

#### 3.4、迷题揭晓

有了上面第三节背景知识，对第二节给出的题，想必也有答案了。

首先由于`i`在函数定义的返回值上声明，因为根据Go的`caller-save`模式，`i`变量会存储在main函数的栈空间。

然后，`func1`的return重新把5赋值给了`i`,此时`i=5`

由于闭包函数存储了变量`i`的指针。

因此最后在defer中对`i`进行处增，是直接更新到`i`的指针上，此时`i = 5+1`，所以最终打印出来的结果是6

```go
func func1() (i int) {
    i = 10
    defer func() {
        i += 1
    }
    return 5
}

func main() {
    closure := func1()
    fmt.Println(closure) // output 6
}
```

#### 3.5、再度变题

下面示例

`func1`的返回值不写变量名`i` ，然后原先返回具体字面量，现在改成变量`i`，不是这两小小的改动，会导致运行结果大大不同。

```go
func func1() (int) {
    i := 10
    defer func() {
        i += 1
    }
    return i
}

func main() {
    closure := func1()
    fmt.Println(closure) // output 10
}
```

如果你在返回值里写了变量名，那么该变量会存储在main的栈空间里，如果你不写，那么`i`只能存储在`func1`的栈空间里，与此同时，return的值，不会作用于原变量`i`上，而是会存储在该函数的另外一块栈空间里。

因此你在defer中对原`i`进行自增，并不会作用到`func1`的返回值上。所以打印结果只能是10。

#### 3.6、最后一个问题

在第一节示例中，`sum`是存储在堆内存中的，而后面几个示例都是存储在栈内存里。这是为什么？

仔细对比，不难发现，示例一返回的是闭包函数，闭包函数在`adder`返回后还要在其它地方继续使用，这种情况下，为了保证闭包函数的正常运行，无论闭包函数在哪里，`i`都不能回收，所以Go编译器会智能的将它分配到堆上。

后面的其它示例，都只是涉及了闭包的特性，并不是直接把闭包函数返回，因此完全可以将其分配在栈上。

#### 3.7、总结

1、**闭包函数里引用的外部变量，是在堆还是栈内存申请的。**取决于，你这个闭包函数在函数return后是否还会在其它地方使用，如果会，就会在堆上申请，如果不会，就在栈上申请。

2、闭包函数里，引用的外部变量，存储的并不是对值的拷贝，存的是值的指针。

3、函数的返回值里若写了变量名，则该变量是在上线的栈内存里申请的，return的值，会直接赋值给该变量。

### 4、defer的变量快照什么情况会失效？

下面示例中，会先打印出`18`，即使后面`age`被改变了，可`defer`中的`age`还是修改之前的`0`，这种现象称之为变量快照。

```go
func func1() {
    age := 0
    defer fmt.Println(age) // output : 0
    
    age = 18
    fmt.Println(age) // output : 18
}

func main() {
    func1()
}
```

下面这个示例，看下会输出什么？

```go
func func1() {
    age := 0
    defer func() {
        fmt.Println(age)
    }()
    age = 18
    return
}

func main() {
    func1()
}
```

输出结果是`18`，而不是0

仔细观察会发现，上面两个示例的区别在于，一个defer后接的是单个表达式，另外一个defer后接的是一个函数，并不是普通函数，而是一个匿名闭包函数。根据闭包的特性，实际上在闭包函数存的是这`age`这个变量的指针，因此在defer后修改的值会直接影响到defer中`age`的值。

总结：

1、若defer后接的是单行的表达式，那defer中的age只是拷贝了`func1`函数栈中的defer之前的age的值。

2、若defer后接的是闭包函数，那defer中的age只是存储的是`func1`函数栈中age的指针。

### 5、说说你对Go里的抢占式调度的理解

Go从v1.1发展到目前的v1.16，协和调度策略也在不断的完善优化。

#### v1.1 的非抢占式调用

在最初的v1.1版本中，只有当一个协程主动让出CPU资源(可以是运行结束，也可以是发生了系统调用或其它阻塞性操作)，才能触发调度，进行下一个协程。

而如果一个协程运行了很久，也没有主动让出的动作发生，就会自私的一个人占用整个线程，该线程也无法再去运行其它的goroutine了。

#### v1.2 基于协作的抢占式调用

由于v1.1的非抢占式调用，以程序的并发效率影响实在太大，在下一个版本v1.2就紧急地对调度策略进行了临时的优化。经过优化后，Go从v1.2开始支持抢占式的调用。

1. 如果sysmon监控线程发现有个协程A执行时间太长了（或者 GC场景，或者stw场景），那么会友好的在这个A协程的某个字段设置一个抢占标记。
2. 协程A在call一个函数的时候，会复用到扩容栈（morestack）的部分逻辑，检查到抢占标记之后，让出CPU，切到调度主协程里。

之所以说v1.2的抢占式调用是临时优化方案，是因为这种抢占式调度是基于协作的。在一些的边缘场景下，协和还是会独自占用整个线程无法让出。

从上面流程中，可以注意到，A调度权被抢占有个前提，A必需主动call函数，这样才能有走到morestack的机会。

反而案例可以看下面这个程序，当运行到`time.Sleep`后，线程上的goroutine会从main切换到当前的匿名函数协程，而这个匿名函数协程是在做for死循环，并没有任何可以让出CPU运行权的操作，因为该程序在go1.14之前的Go版本中，运行后会一直卡住，而不会打印`I got scheduled!`

```go
func main() {
	runtime.GOMAXPROCS(1)
    fmt.Println("The program starts ...")
    
    go func() {
        for { } 
    }()
    
    time.Sleep(time.Second)
    fmt.Println("I got scheduled!")
}
```

#### v1.14 基于信号的抢占式调用

基于协作的抢占式调用，伴随着Go走过了12个版本，终于在v1.14迎来了真正的抢占式调用。

为什么说是真正的抢占式调用呢？

因为v1.14的这种抢占式调用是基于信号的，不管你的协程有没有意愿主动让出CPU运行权，只要你这个协程超过某个时间，就会发送信号强行夺取CPU运行权。这个时间是20ms。

### 6、简述下Go的栈空间的扩容/缩容过程？

#### 扩容流程

**为什么会有栈空间扩容**

由于当前的Go的栈结构使用的是连续栈，并且初始值才有2k比较小，因此随着函数的调用层级加深，Go的初始栈空间就可能不够用，不够用的话，就会触发栈空间的扩容。

**栈空间扩容什么时候会触发**

编译器会为函数调用插入运行时检查`runtime.morestack`，它会在几乎所有的函数调用之前检查当前`goroutine`的栈内存是否充足，如果当前栈需要扩容，会调用`runtime.newstack`创建新的栈。

而新的栈空间，是旧栈空间大小（通过保存在`goroutine`中的`stack`信息里记录的栈区内存边界计算出来）的两倍，但最大栈空间大小不能超过`maxstacksize`，也就是1GB。

#### 缩容流程

**为什么会有栈空间缩容**

在函数返回后，对应的栈空间会回收，如果调用栈比较深，那么随着函数一个一个返回，回收的栈空间会越来越多，假设在调用栈最深的时候，整体空调扩容到了100M，那么随着函数的返回，到某一个函数的时候，100M的栈空间只有1M的实际占用，内存利用庇只有1%，实在太浪费了。

**栈空间缩容什么时候会触发**

在垃圾回收的时候，有必要检查一下栈空间里面内存利用率，当利用率低于25%时，就要开始进行缩容，缩容成原来栈空间的50%，但同时也不能小栈空间原始值，2KB。

**相同点**

不管是扩容还是缩容，都是使用`runtime.copystack`函数来开辟新的栈空间，然后将旧栈的数据全部拷贝至新的栈空间，并调整原来指针的指向。

### 7、说下GMP模型的原理

#### 7.1、什么是GMP

- **G**：Rotoutine，也就是go里的协和，是用户态的轻量级线程，具体可以创建多个goroutine，取决你的内存有多大，一个goroutine大概需要4k内存，只要你不是在32位的机器上，那么创建个几百万个的goroutine应该没有问题。
- **M**：Thred，也就是操作系统线程，Go runtime最多允许创建10000个操作系统线程，超过了就会抛出异常
- **P**：Processor，处理器，数量默认等于机器的CPU核心数，若想调小，可以通过GOMAXPROCS这个环境变量设置。

#### 7.2、GMP核心

**两个队列**

在整个Go调度器的生命周期中，存在着两个非常重要的队列：

- 全局队列（Global Queue）：全局只有一个
- 本地队列（Local Queue）：每个P都会维护一个本地队列 

当你执行 `go func()`创建一个goroutine时，会优先将该协程放入到当前P的本地队列中等待被P选中执行。

若当前P的本地队列任务太多了，已经存放不下了，那么这个goroutine就只能放入到全局队列中。

**两种调度**

一个协程得以运行，需要同时满足以下两个条件：

1. P已经和某个线程进行绑定，这样才能参与操作系统 的调度获得CPU时间
2. P已经从队列中（可以是本地队列，也可以是全局队列，甚至是从其它P的队列）取到该协程

每一个操作就是**操作系统调度**，第二个就是**Go里的调度器**。

**操作系统调度**

假如一台机器上有两个CPU核心，意味着，同时在同一时间里，只能有两个线程运行着。

如果该机器上实际开户了4个线程，要是先执行一个线程完再执行另外一个线程，那么当某一个线程因为一些阻塞性的系统调用而阻塞时，CPU的时间就会因止浪费掉。

合适的作法是，使用**操作系统调度策略**，设定一个调度周期，假设是10ms，那在一个周期里，每个线程都平均分，都只能得到2.5ms的CPU运行时间。

如果机器上有1000个线程呢？难道每个线程都分个0.01ms吗？

要知道，CPU从A线程切换到B线程，是有巨大的时间浪费在线程上下文的切换，如果切换得太频繁，就会有大量的CPU时间浪费。

![CPU工作时间](http://image.iswbm.com/20210904140447.png)

因此，通常会限制最小的时间片长度，假设国2ms，受此调整，现在调度周期就会变成2*1000=2s

**Go调度器**

在go中需要用到调蓄的，无非是如下几种：

**将P绑定到一个合适的M**

假设P1当前正绑定在M1上运行G1，此时G1内部发生了一次系统调度后，P1就会与M1进行解绑，然后从空闲的线程队列中再寻找一个来绑定，假设绑定的是M2，可如果没有空闲的线程呢？那没办法，只能创建一个新的线程再进行绑定。

绑定后，就会再从本地的队列中寻找G来执行（如果没找到，就会去其它队列找）。

过了一段时间后，之前的M1上G1发生的系统调用结束后，M1会去找原先自己的搭档P1（它自己会记录），如果自己的老搭档也刚好空闲着，就可以再将合作进行绑定，接着运行G1未完成的工作。

可不幸的是，P1已经找到了新的合作伙伴M2，暂时没空搭理M1.

M1暂时联系不上P1，只能去寻找有没有其它空间的P，如果所有的P都被绑定着，说明现在任务非常繁重，想完成任务就只能排队慢慢等。

于是，M1上的G1就会被标记为Runable，放到全局队列中，而M1自身也会因为没有P可以绑定而进入休眠状态，如果长时间休眠等待，则会被GC回收销毁。

**为P选中一个G来执行**

P就像是一个流水线工人，而P的本地队列就是流水线，G是流水线上的零件，而Go调度器就是流水线组长，负责监督工作的是不是有在努力工作。

完成一个G后，P就得立马从队列中拿到下一个G，继续干活。

遇到手脚麻利的P，干完了自己的活，本想着可以偷懒一会，没想到却被组长发现了，立马就从全局队列中拿了些新的G交到P的手里。

天真的P以为只要把全局队列里的G也干完了，就肯定能休息了吧？

当P又快手快脚的把全局队列中的G也都干完的时候，P非常得意，心想：终于可以休息会了。

没想到又被眼尖的组长察觉到了：不错啊，小P手脚挺麻利的。看看其他人，还那么多活没干完。真是拖后腿，可谁让咱们是一个团队呢？需要集体荣誉感，你能者多劳。

说完，就把其他人的G放到小P身上。。。

#### 7.3、调度器的设计策略

**复用线程**

避免频繁的创建，销毁线程，而是对线程的复用。

**1、Work Sealing机制**

当本线程无可运行的G时，尝试从其他线程绑定的P偷取G，而不是销毁线程。

**2、hand off机制**

当本线程因为G进行系统调用阻塞时，线程释放绑定的P，把P转换给其他空闲的线程执行。

**利用并行**

GOMAXPROCS设置P的数量，最多有GOMAXPROCS个线程分布在多个CPU上同时运行。GOMACPROCS也限制了并发的程度，比如GOMAXPROCS = 核数/2，则最多利用了一半的CPU核进行并行。

**抢占调度**

在Go中，一个goroutine最多占用CPU10ms，防止 其它goroutine被饿死，这是协作式抢占调度。

在Go 1.14+版本开始，Go开始基于信号的真抢占调度了。

**全局G队列**

在全新的调度器中依然有全局的G队列，但功能已经被弱化了，当M执行work stealing从其他P偷不到G时，它可以丛全局的G队列获取G。

### 8、GMP模型为什么要有P？

#### GM模型是怎么样的？

在Go v1.1之前，实际上GMP确实是没有P的，所有的M线程都要从全局队列中获取G来执行任务，为了避免冲突，从全局队列中获取G的时候，要先获取一把大锁。

当一个程序的并发量比较小的时候，影响还不大，而当程序的并发量非常大的时候，这个全局队列会成为性能的瓶颈。

除此之外，若直接把G从全局队列分配给M，那么当G中系统调用或者其他阻塞性的操作时，M会有一段时间处于挂起的状态，此时又没有新创建线程和线程来代替该线程继续从队列中取出其他G来运行，从效率上会大打折扣。

**P带来的改变**

加入了P后会带来什么改变呢？

- 每个P有自己的本地队列，大幅度的减轻了对全局直接依赖，所带的效果就是锁竞争的减少。而GM模型的性能开销大头就是锁竞争。
- 当一个M中运行的G发生阻塞性操作时，P会重新选择一个M，若没有M就会新创建一个M来继续从P本地队列中取G来执行，提高运行效率。
- 每个P相对的平衡上，在MGP也实现了Work Stealing算法，如果P的本地队列为空，则会从全局队列或其他P的的本地队列中窃取可以运行的G来运行，减少空转，提高了资源利用庇。

### 9、不分配内存的指针类型能用吗？

下面这个例子，先定义了一个类型为`*int`的指针类型，可是然后把10赋值给指针指向的值

```go
func main() {
    var i *int
    *i = 10
    fmt.PRintln(*i)
}
```

代码运行报空指针异常

```shell
panic: runtime error: invalid memory address or nil pointer dereference [recovered]
	panic: runtime error: invalid memory address or nil pointer dereference
[signal 0xc0000005 code=0x1 addr=0x0 pc=0xf16916]
```

这里我们只声明了指针类型，并没有为它分配内存，也没有内存地址，你赋值给它的值应该存哪里呢？所以运行时候就报空指针异常了。

正确的示例：在赋值前，先用new函数给i分配内存。

```go
func main() {
    var i *int
    i = new(int)
    *i = 10
    fmt.Println(i)
}
```

### 10、如何让在强制转换类型时，不发生内存拷贝？

当你使用要对一个变量从一个类型强制转换成另一个类型，其实都会发生内存的拷贝，而这种拷贝会对性能有所影响的，因此如果可以在转换的时候避免内存的拷贝就了了。

庆幸的是，在一些特定的类型下，这种想法确实是可以实现的。

比如将字符串转成 []byte 类型。

正常的转换方法是

```go
// string to []byte
s1 := "hello"
b := []byte(s1)
// []byte to string
s2 := string(b)
```

具体的代码如下

```go
func main() {
    msg1 := "hello"
    sh := *(*reflect.StringHeader)(unsafe.Pointer(&msg1))
    bh := reflect.SliceHeader{
        Data: sh.Data,
        Len: sh.Len,
        Cap: sh.Len,
    }
    msg2 := *(*[]byte)(unsafe.Pointer(&bh))
    fmt.Printf("%v \n",msg2)
}
```

上面代码核心知识点有三个：

1. 一种定义变量的怪异方法
2. 字符串的底层数据结构
3. 切片的底层数据结构

正常我们用的变量声明定义方法如下面两种

```go
// 第一种
var name string = "GO 语言"
// 第二种
name := "Go 语言"
```

还有一种方法

```go
name := (string)("Go 语言")
```

第一个括号里的是指针类型，第二个括号里的是指针的值。

通过`unsafe.Pointer`就可以将`&msg`指针的内存地址取出来。

两个括号合起来就是，声明并定义了一个`*reflect.StringHeader`类型的指针变量，对应的指针值还是原来msg1的内存地址。

最前面那个`*`，应该都知道，是从`*reflect.StringHeader`类型的指针变量中取出值。

那int、bool、string这些类型知道，但这个reflect.StringHeader是什么类型？

它就是字符串的底层结构，是字符串最原始的样子。

```go
type StringHeader struc {
    Data uintptr
    Len int
}
```

同样的`Sliceheader`则是切片的底层数据结构

```go
type Sliceheader struct {
    Data uintptr
    Len int
    Cap int
}
```

是不是觉得很像，只要把`StringHeader`里的Data塞给`SliceHeader`里的Data，再把`StringHeader`里的Len塞给`SliceHeader`里的Len和Cap就不费空间创造出一个新的变量。

```go
	bh := reflect.SliceHeader{
        Data: sh.Data,
        Len: sh.Len,
        Cap: sh.Len,
    }
```

最后再把`SliceHeader`通过上面的强制转换方法，再转成`[]byte`就可以了，中间就不会有任何的内存拷贝过程。

下面是完整的测试示例

```go
// string to []byte
func String2Bytes(s string) []byte {
    sh := (*reflect.StringHeader)(unsafe.Pointer(&s))
    bh := reflect.SliceHeader{
        Data: sh.Data,
        Len:  sh.Len,
        Cap:  sh.Len,
    }
    return *(*[]byte)(unsafe.Pointer(&bh))
}

// 测试标准转换[]byte性能
func Benchmark_NormalString2Bytes(b *testing.B) {
    x := "Hello Gopher! Hello Gopher! Hello Gopher!"
    for i := 0; i < b.N; i++ {
        _ = []byte(x)
    }
}

// 测试强转换string到[]byte性能
func Benchmark_String2Bytes(b *testing.B) {
    x := "Hello Gopher! Hello Gopher! Hello Gopher!"
    for i := 0; i < b.N; i++ {
        _ = String2Bytes(x)
    }
}

// 单元测试
func TestString2Bytes(t *testing.T) {
    x := "Hello Gopher!"
    y := String2Bytes(x)
    z := []byte(x)
    if !bytes.Equal(y, z) {
        t.Fail()
    }
    fmt.Println("= = = = =")
}
```

### 11、Go中的GC演变是怎样的？

#### 标记清除法

在GoV1.3之前采用的是 标记-清除（mark and sweep）算法

逻辑是，先将整个程序挂起（STW， stop the world），然后遍历程序中的对象，只要是可达的对象，都会被会标记保留（红色），而那些不可达的对象（白色），则会被清理掉，清理完成后，会恢复程序。然后不断重复该过程。

![](http://image.iswbm.com/20210905105841.png)

这种标记-清除的算法，会有一段STW的时间，将整个程序暂停，这对于一些实时性要求比较高的系统是无法接受的。

上面这个标记的过程扫描的是整个堆内存，耗时比较久，最重要的是，它在清除数据的时候，会产生堆内存的碎片。

#### 三色并发标记法

在GoV1.5开始，抛弃标记-清除这种算法，改用**三色并发标记法**

新的算法出现，必然是要解决旧算法存在的最关键问题，即STW的暂停挂起导致的程序卡顿。

它的逻辑是，准备三种颜色，分别对三种对象进行标记：

- 黑色：检测到有被引用，并且已经遍历完它所有直接引用的对象或者属性
- 白色：还没检测到有引用的对象（检测开始前，所有对象都是白色，检测结束后，没有被引用的对象都是白色，会被清除掉）
- 灰色：检测到有被引用，但他们的属性还没有遍历完，等遍历完后也会变成黑色

既然STW会挂起程序，那是不是可以考虑将其摘除呢？

摘除会带来一个问题，就是在标记的时候，程序的运行会不断改变对象的引用路径，影响标记的准确性。

总结来说，就是在当标记的时候出现：**一个白色对象被黑色对象引用，同时该白色对象又被某个灰色（或者上级有灰色对象）对象取消引用的情况**，就会标记不准确。

如果想要摘除STW，那就要规避掉上面这种场景出现。

解决方法是，使用**插入屏障**和**删除屏障**

**插入屏障**

在A对象引用B对象的时候，B对象被标记为灰色。（将B挂在A下游，B必须被标记为灰色）

**删除屏障**

被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。



参考文档：[\[典藏版]Golang三色标记、混合写屏障GC模式图文全分析](https://segmentfault.com/a/1190000022030353)

### 12、GO中哪些动作会触发runtime调度？

goroutine在遇到哪些情况会触发runtime的调度器去调度呢？

#### 第一种：系统调用 SysCall

当你在来goroutine进行一些sleep休眠、读取磁盘或者发送网络请求时，其实都会发生系统调用，进入操作系统内核。

而一旦发生系统调用，就会直接触发runtime的调度，当前的P就会去找其他的M进行绑定，并取出G开始运行。

#### 第二种：等待锁，通道

在代码中，若因为锁或者通道导致代码阻塞了，也会触发调度。

#### 第三种：人工触发

在代码中直接调用runtime.Gosched方法，也可以手动触发。

还有就是在执行fmt.Println的时候也会触发调度。